{
  "id": "1298225b5539415bad0615d711adec7d",
  "type": "backlog",
  "source": "instapaper_csv",
  "payload": {
    "row": {
      "URL": "https://www.theverge.com/2018/10/7/17940352/turing-test-one-word-minimal-human-ai-machine-poop",
      "Title": "A one-word Turing Test suggests \u2018poop\u2019 is what sets us apart from the machines The Verge",
      "Selection": "Imagine that you\u2019re living in some dystopian future, and you have been accused of being an advanced AI, which is outlawed in this society. The penalty is death, and in order to convince the judge who will decide your fate, you can utter just one word, any word you like from the dictionary, to prove that you\u2019re flesh and blood. What word do you choose? \n\nIt sounds like the setup for a cheesy sci-fi short, but this is actually part of a curious paper from a pair of researchers at MIT on something they call the \u201cMinimal Turing Test.\u201d \n\nInstead of a machine trying to convince someone they\u2019re human through conversation \u2014 which was the premise of the original Turing Test, outlined by British scientist Alan Turing in his seminal 1950 paper \u201cComputing Machinery and Intelligence\u201d \u2014 the Minimal Turing Test asks for just one word, either chosen completely freely or picked from a pair of words. \n\nThe researchers responsible, John McCoy and Tomer Ullman, clarify that the Minimal Turing Test isn\u2019t a benchmark for AI progress, but a way of probing how humans see themselves in relation to machines. This question is going to become increasingly relevant in a world filled with AI assistants, deepfaked humans, and Google auto reply handling your email. In a world of human-like AI, what do we think sets us apart? What makes us different?\n\nIn the first of McCoy and Ullman\u2019s two tests, 936 participants were asked to select any word they liked that they thought could be proof of their humanity. Despite the free range of choices, results clustered around a small number of themes. The four most frequently picked words were \u201clove\u201d (134 answers), \u201ccompassion\u201d (33 answers), \u201chuman\u201d (30 answers), and \u201cplease\u201d (25 answers), which made up a quarter of all responses. Other clusters were empathy (words like \u201cemotion,\u201d \u201cfeelings,\u201d and \u201csympathy\u201d), and faith and forgiveness (words like \u201cmercy,\u201d \u201chope,\u201d and \u201cgod\u201d). \n\nAll in all, the 936 answers covered 428 individual words, which is a striking amount of cohesion.\n\n        Answers from the one-word test show the most popular single answer was \u201clove.\u201d \n\n        Image by McCoy and Ullman / MIT\n\nIn the second test, 2,405 participants had to choose between pairs of words, deciding which of the two they thought was given by a human and a machine. Again, words like \u201clove,\u201d \u201chuman,\u201d and \u201cplease\u201d scored strongly, but the winning word was simpler and distinctly biological: \u201cpoop.\u201d Yes, out of all of the word pairings, \u201cpoop\u201d was selected most frequently to denote the very essence and soul of humanity. Poop.\n\nSpeaking to The Verge, McCoy of MIT\u2019s Sloan Neuroeconomics Laboratory, stressed that the test was more about social psychology than computer science. \n\n\u201cWe don\u2019t see it being used as the next CAPTCHA,\u201d McCoy says. \u201cThe practical applications it has in the AI computer space is more when you\u2019re thinking about user interface design and things like that. In those contexts, it\u2019s perhaps useful to know how people think about computers and what they think sets them apart.\u201d \n\nThe Turing Test isn\u2019t a good benchmark of AI intelligence by itself\n\nThis makes sense, as even the original Turing Test has long fallen out of favor with computer scientists as a test of machine intelligence. Critics say that it tests the ability of programmers to find conversational hacks that can trick humans more than intelligence. \n\nFor example, in 2014, news coverage pronounced that the Turing Test had been passed by a chatbot. The programmers tricked judges by having their bot identify itself as a 13-year-old Ukrainian boy named Eugene Goostman. This provided the perfect cover for the bot\u2019s many mistakes and its inability to answer certain questions. As critics like computer scientist Gary Marcus noted, \u201cWhat Goostman\u2019s victory really reveals ... is not the advent of SkyNet or cyborg culture but rather the ease with which we can fool others.\u201d\n\nBut this isn\u2019t to say that the Turing Test is useless. Creating computer programs that can chat convincingly is a fruitful challenge for AI researchers that may benefit humanity. The test is also still a fantastic thought experiment that can help us explore complex questions surrounding our understanding of intelligence. We can also modify it to sharpen its focus by asking computers not to simply chat, but to answer queries that require a nuanced and rich understanding of the world. (One example is asking a computer, \u201cWhat are the plurals of \u2018platch\u2019 and \u2018snorp\u2019?\u201d A human would probably answer \u201cplatches\u201d and \u201csnorps,\u201d despite the fact that these words are nonsense and can\u2019t be found in a dictionary.)\n\nIt\u2019s in this framework that the Minimal Turing Test is best appreciated as a thought experiment, not a benchmark for AI progress. McCoy says what surprised him most about the research was just how much creativity there was in the answers. \u201cPeople came up with all sorts of interesting shibboleths and puns,\u201d he says, with words like \u201cbootylicious\u201d \u201csupercalifragilisticexpialidocious.\u201d (Try spelling that without Google.) \n\n\u201cIt tells you something about the gap between humans and smart robots,\u201d says McCoy, \u201cthat people who have never had to think about this situation before came up with a lot smart and funny results.\u201d It\u2019s something, in other words, that a computer would struggle with. \n",
      "Folder": "Feedly",
      "Timestamp": "1538936438",
      "Tags": "[]"
    },
    "source_path": "data/backlog/source_drops/Instapaper-Export-2025-03-26_20_23_56.csv"
  },
  "origin_manifest_id": "497cd2c549404409861b3a1098bd5186",
  "created_at": "2025-11-28T05:10:23.467782Z"
}