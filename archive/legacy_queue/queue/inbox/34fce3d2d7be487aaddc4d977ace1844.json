{
  "id": "34fce3d2d7be487aaddc4d977ace1844",
  "type": "backlog",
  "source": "instapaper_csv",
  "payload": {
    "row": {
      "URL": "https://stratechery.com/2016/fake-news/",
      "Title": "Fake News Stratechery by Ben Thompson",
      "Selection": "Between 2001 and 2003, Judith Miller wrote a number of pieces in the New York Times asserting that Iraq had the capability and the ambition to produce weapons of mass destruction. It was fake news.\n\nLooking back, it\u2019s impossible to say with certainty what role Miller\u2019s stories played in the U.S. ill-fated decision to invade Iraq in 2003; the same sources feeding Miller were well-connected with the George W. Bush administration\u2019s foreign policy team. Still, it meant something to have the New York Times backing them up, particularly for Democrats who may have been inclined to push back against Bush more aggressively. After the all, the New York Times was not some fly-by-night operation, it was the preeminent newspaper in the country, and one generally thought to lean towards the left. Miller\u2019s stories had a certain resonance by virtue of where they were published.\n\nIt\u2019s tempting to make a connection between the Miller fiasco and the current debate about Facebook\u2019s fake news problem; the cautionary tale that \u201cfake news is bad\u201d writes itself. My takeaway, though, is the exact opposite: it matters less what is fake and more who decides what is news in the first place.\n\nFacebook\u2019s Commoditization of Media\n\nIn Aggregation Theory I described the process by which the demise of distribution-based economic power has resulted in the rise of powerful intermediaries that own the customer experience and commoditize their suppliers. In the case of Facebook, the social network started with the foundation of pre-existing offline networks that were moved online. Given that humans are inherently social, users started prioritizing time on Facebook over time spent reading, say, the newspaper (or any of the effectively infinite set of alternatives for attention).\n\nIt followed, then, that it was in the interest of media companies, businesses, and basically anyone else who wanted to get the attention of users, to be on Facebook as well. This was great for Facebook: the more compelling content it could provide to its users, the more time they would spend on Facebook; the more time they spent on Facebook, the more opportunities Facebook would have to place advertisements in front of them. And, critically, the more time users spent on Facebook, the less time they had to read anything else, increasing the motivation for media companies (and businesses of all types) to be on Facebook themselves, resulting in a virtuous cycle in Facebook\u2019s favor: by having the users Facebook captured the suppliers, which deepened their hold on the users, increasing their power over suppliers.\n\nThis process reduced Facebook\u2019s content suppliers \u2014 media companies \u2014 into pure commodities. All that mattered for everyone was the level of engagement: media companies got ad views, Facebook got shares, and users got the psychic reward of having flipped a bit in a database. Of course not all content was engaging to all users; that\u2019s what the algorithm was for: show people only what they want to see, whether it be baby pictures, engagement announcements, cat pictures, quizzes, or, yes, political news. It was, from Facebook\u2019s perspective \u2014 and, frankly, from its users\u2019 perspective \u2014 all the same. That includes fake news too, by the way: it\u2019s not that there is anything particularly special about news from Macedonia, it\u2019s that according to the algorithm there isn\u2019t anything particularly special about any content, beyond the level of engagement it drives.\n\nThe Media and Trump\n\nThere has been a lot of discussion \u2014 in the media, naturally \u2014 about how the media made President-elect Donald Trump. The story is that Trump would have never amounted to anything had the media not given him billions of dollars worth of earned media \u2014 basically news coverage (as opposed to paid media, which is advertising) \u2014 and that the industry needed to take responsibility. It\u2019s a lovely bit of self-reflection that lets the industry deny the far more discomforting reality: that the media couldn\u2019t have done a damn thing about Trump if they had wanted to.\n\nThe reason the media covered Trump so extensively is quite simple: that is what users wanted. And, in a world where media is a commodity, to act as if one has the editorial prerogative to not cover a candidate users want to see is to face that reality square in the face absent the clicks that make the medicine easier to take.\n\nIndeed, this is the same reason fake news flourishes: because users want it. These sites get traffic because users click on their articles and share them, because they confirm what they already think to be true. Confirmation bias is a hell of a drug \u2014 and, as Techcrunch reporter Kim-Mai Cutler so aptly put it on Twitter, it\u2019s a hell of a business model.\n\nWhy Facebook Should Fix Fake News\n\nSo now we arrive at the question of what to do about fake news. Perhaps the most common sentiment was laid out by Zeynep Tufekci in the New York Times: Facebook should eliminate fake news and the filter effect \u2014 the tendency to see news you already agree with \u2014 while they\u2019re at it. Tufekci writes:\n\nMark Zuckerberg, Facebook\u2019s chief, believes that it is \u201ca pretty crazy idea\u201d that \u201cfake news on Facebook, which is a very small amount of content, influenced the election in any way.\u201d In holding fast to the claim that his company has little effect on how people make up their minds, Mr. Zuckerberg is doing real damage to American democracy \u2014 and to the world\u2026\n\nThe problem with Facebook\u2019s influence on political discourse is not limited to the dissemination of fake news. It\u2019s also about echo chambers. The company\u2019s algorithm chooses which updates appear higher up in users\u2019 newsfeeds and which are buried. Humans already tend to cluster among like-minded people and seek news that confirms their biases. Facebook\u2019s research shows that the company\u2019s algorithm encourages this by somewhat prioritizing updates that users find comforting\u2026\n\nTufekci offers up a number of recommendations for Facebook, including sharing data with outside researchers to better understand how misinformation spreads and the extent of filter bubbles, 1 acting much more aggressively to eliminate fake news like it does spam or other objectionable content, rehiring human editors, and retweaking its algorithm to favor news balance, not just engagement.\n\nWhy Facebook Should Not\n\nAll seem reasonable on their face, but in fact Tufekci\u2019s recommendations are radical in their own way.\n\nFirst, there is no incentive for Facebook to do any of this; while the company denies this report in Gizmodo that the company shelved a change to the News Feed algorithm that would have eliminated fake news stories because it disproportionately affected right-wing sites, the fact remains that the company is heavily incentivized to be perceived as neutral by all sides; anything else would drive away users, a particularly problematic outcome for a social network.2\n\nMoreover, any move away from a focus on engagement would, by definition, decrease the time spent on Facebook, and here Tufekci is wrong to claim that this is acceptable because there is \u201cno competitor in sight.\u201d In fact, Facebook is in its most challenging position in a long time: Snapchat is stealing attention from its most valuable demographics, even as the News Feed is approaching saturation in terms of ad load, and there is a real danger Snapchat beats the company to the biggest prize in consumer tech: TV-centric brand advertising dollars.\n\nThere are more even more fundamental problems, though: how do you decide what is fake and what isn\u2019t? Where is the line? And, perhaps most critically, who decides? To argue that the existence of some number of fake news items amongst an ocean of other content ought to result in active editing of Facebook content is not simply a logistical nightmare but, at least when it comes to the potential of bad outcomes, far more fraught than it appears.\n\nThat goes doubly-so for the filter bubble problem: there is a very large leap from arguing Facebook impacts its users\u2019 flow of information via the second-order effects of driving engagement, to insisting the platform actively influence what users see for political reasons. It doesn\u2019t matter that the goal is a better society, as opposed to picking partisan sides; after all, partisans think their goal is a better society as well. Indeed, if the entire concern is the the outsized role that Facebook plays in its users\u2019 news consumption, then the far greater fear should be the potential of someone actively abusing that role for their own ends.\n\nI get why top-down solutions are tempting: fake news and filter bubbles are in front of our face, and wouldn\u2019t it be better if Facebook fixed them? The problem is the assumption that whoever wields that top-down power will just so happen to have the same views I do. What, though, if they don\u2019t? Just look at our current political situation: those worried about what Trump have to contend with the fact that the power of the executive branch has been dramatically expanded over the decades; we place immense responsibility and capability in the hands of one person, forgetting that said responsibility and capability is not so easily withdrawn if we don\u2019t like the one wielding it.\n\nTo that end I would be far more concerned about Facebook were they to begin actively editing the News Feed; as I noted last week I\u2019m increasingly concerned about Zuckerberg\u2019s utopian-esque view of the world, and it is a frighteningly small step from influencing the world to controlling the world. Just as bad would be government regulation: our most critical liberty when it comes to a check on tyranny is the freedom of speech, and it would be directly counter to that liberty to put a bureaucrat \u2014 who reports to the President \u2014 in charge of what people see.\n\nThe key thing to remember is that the actual impact of fake news is dependent on who delivers it: sure, those Macedonian news stories aren\u2019t great, but their effect such as it is comes from confirming what people already believe. Contrast that to Miller\u2019s stories in the New York Times: because the New York Times was a trusted gatekeeper, many people fundamentally changed their opinions, resulting in a disaster the full effects of which are still being felt. In that light, the potential downside of Facebook coming anywhere close to deciding the news can scarcely be imagined.\n\nLiberty and Laziness\n\nThere may be some middle ground here: perhaps some sources are so obviously fake that Facebook can easily exclude them, ideally with full transparency about what they are doing and why. And, to the extent Facebook can share data with outside researchers without compromising its competitive position, it should do so. The company should also provide even more options to users to control their feed if they wish to avoid filter bubbles.\n\nIn truth, though, you and I know that few users will bother. And that, seemingly, is what bothers many of Facebook\u2019s critics the most. If users won\u2019t seek out the \u201cright\u201d news sources, well, then someone ought to make them see them. It all sounds great \u2014 and, without question, a far more convenient solution to winning elections than actually making the changes necessary to do so \u2014 until you remember that that someone you just entrusted with such awesome power could disagree with you, and that the very notion of controlling what people read is the hallmark of totalitarianism.\n\nLet me clear: I am well aware of the problematic aspects of Facebook\u2019s impact; I am particularly worried about the ease with which we sort ourselves into tribes, in part because of the filter bubble effect noted above (that\u2019s one of the reasons Why Twitter Must Be Saved). But the solution is not the reimposition of gatekeepers done in by the Internet; whatever fixes this problem must spring from the power of the Internet, and the fact that each of us, if we choose, has access to more information and sources of truth than ever before, and more ways to reach out and understand and persuade those with whom we disagree. Yes, that is more work than demanding Zuckerberg change what people see, but giving up liberty for laziness never works out well in the end.\n\nFor more about the Internet has fundamentally changed politics, please see this piece from March, The Voters Decide.\n\nFacebook has done a study about the latter, but as Tufekci and others have documented, the study was full of problems [\u21a9]\n\nIndeed, it wasn\u2019t that long ago that I was making this exact argument in response to those who insisted Facebook would alter the News Feed to serve their own political purposes [\u21a9]\n",
      "Folder": "Feedly",
      "Timestamp": "1479344084",
      "Tags": "[]"
    },
    "source_path": "data/backlog/source_drops/Instapaper-Export-2025-03-26_20_23_56.csv"
  },
  "origin_manifest_id": "497cd2c549404409861b3a1098bd5186",
  "created_at": "2025-11-28T05:10:23.753949Z"
}