#!/usr/bin/env python3
"""
Stress Load Testing Suite

Test the system under heavy load to verify performance,
stability, and resource management.
"""

import sys
import os
import asyncio
import time
import threading
import random
import string
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Any

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from core.database import get_database, Content
from core.processor import get_processor


class StressLoadTests:
    """Comprehensive stress and load testing suite"""

    def __init__(self):
        self.db = get_database()
        self.processor = get_processor()
        self.test_results = []
        self.created_content_ids = []
        self.start_time = time.time()

    def log_test(self, test_name: str, passed: bool, details: str = ""):
        """Log test result with timing"""
        elapsed = time.time() - self.start_time
        status = "‚úÖ" if passed else "‚ùå"
        self.test_results.append({
            'test': test_name,
            'passed': passed,
            'details': details,
            'elapsed': elapsed
        })
        print(f"{status} {test_name} ({elapsed:.2f}s) - {details}")

    def generate_test_content(self, length: int = 100) -> str:
        """Generate random test content"""
        words = ['lorem', 'ipsum', 'dolor', 'sit', 'amet', 'consectetur',
                'adipiscing', 'elit', 'sed', 'do', 'eiusmod', 'tempor',
                'incididunt', 'ut', 'labore', 'et', 'dolore', 'magna',
                'aliqua', 'enim', 'ad', 'minim', 'veniam', 'quis', 'nostrud']
        return ' '.join(random.choice(words) for _ in range(length))

    def generate_test_title(self) -> str:
        """Generate random test title"""
        adjectives = ['Advanced', 'Basic', 'Complex', 'Simple', 'Modern',
                      'Traditional', 'Efficient', 'Robust', 'Scalable', 'Secure']
        nouns = ['System', 'Application', 'Framework', 'Platform', 'Service',
                 'Component', 'Module', 'Interface', 'Architecture', 'Solution']
        return f"{random.choice(adjectives)} {random.choice(nouns)} {random.randint(1, 999)}"

    async def test_database_connection_pool(self):
        """Test database connection pool under load"""
        print("\nüîå Testing Database Connection Pool...")

        def worker(worker_id: int, operations: int) -> List[int]:
            """Worker for connection pool testing"""
            content_ids = []
            for i in range(operations):
                content = Content(
                    title=f"Connection Pool Test {worker_id}-{i}",
                    content=f"Test content from worker {worker_id}, operation {i}",
                    content_type="stress_test"
                )
                try:
                    content_id = self.db.store_content(content)
                    content_ids.append(content_id)

                    # Small delay to simulate processing
                    time.sleep(0.001)
                except Exception as e:
                    print(f"Worker {worker_id} operation {i} failed: {e}")
            return content_ids

        # Test with increasing concurrency
        concurrency_levels = [5, 10, 20, 50]
        operations_per_worker = 10

        for concurrency in concurrency_levels:
            start_time = time.time()
            with ThreadPoolExecutor(max_workers=concurrency) as executor:
                futures = [executor.submit(worker, i, operations_per_worker)
                          for i in range(concurrency)]
                all_content_ids = []

                for future in as_completed(futures):
                    try:
                        content_ids = future.result()
                        all_content_ids.extend(content_ids)
                    except Exception as e:
                        self.log_test(f"Connection Pool {concurrency}", False, f"Worker error: {e}")
                        continue

            total_time = time.time() - start_time
            total_operations = concurrency * operations_per_worker
            throughput = total_operations / total_time if total_time > 0 else 0

            self.created_content_ids.extend(all_content_ids)
            self.log_test(f"Connection Pool {concurrency} workers", True,
                        f"{total_operations} ops in {total_time:.2f}s ({throughput:.1f} ops/s)")

    async def test_concurrent_content_processing(self):
        """Test concurrent content processing"""
        print("\nüîÑ Testing Concurrent Content Processing...")

        async def processing_worker(worker_id: int, items: int) -> List[Any]:
            """Worker for concurrent processing"""
            results = []
            for i in range(items):
                content = f"Concurrent processing test {worker_id}-{i}: {self.generate_test_content(50)}"
                title = f"Concurrent Test {worker_id}-{i}"

                try:
                    result = await self.processor.process(content, title=title)
                    results.append(result)
                    self.created_content_ids.append(result.content.id)
                except Exception as e:
                    print(f"Processing worker {worker_id} item {i} failed: {e}")
            return results

        # Test with different concurrency levels
        concurrency_tests = [
            (5, 20),   # 5 workers, 20 items each
            (10, 10),  # 10 workers, 10 items each
            (20, 5),   # 20 workers, 5 items each
        ]

        for workers, items_per_worker in concurrency_tests:
            start_time = time.time()
            tasks = [processing_worker(i, items_per_worker) for i in range(workers)]
            all_results = await asyncio.gather(*tasks, return_exceptions=True)

            total_time = time.time() - start_time
            total_items = workers * items_per_worker

            # Count successful results
            successful = 0
            for worker_results in all_results:
                if isinstance(worker_results, list):
                    successful += sum(1 for r in worker_results if hasattr(r, 'success') and r.success)

            throughput = successful / total_time if total_time > 0 else 0
            success_rate = successful / total_items * 100 if total_items > 0 else 0

            self.log_test(f"Concurrent Processing {workers} workers", True,
                        f"{successful}/{total_items} successful ({success_rate:.1f}%) in {total_time:.2f}s ({throughput:.1f} items/s)")

    async def test_memory_usage_under_load(self):
        """Test memory usage under heavy load"""
        print("\nüß† Testing Memory Usage Under Load...")

        import psutil
        import gc

        # Get initial memory usage
        process = psutil.Process()
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB

        # Process large amounts of content
        large_batch_sizes = [100, 500, 1000]

        for batch_size in large_batch_sizes:
            gc.collect()  # Force garbage collection
            start_memory = process.memory_info().rss / 1024 / 1024

            # Generate and process large batch
            batch_content = [self.generate_test_content(200) for _ in range(batch_size)]
            batch_titles = [self.generate_test_title() for _ in range(batch_size)]

            start_time = time.time()
            results = await self.processor.process_batch(batch_content, batch_titles)
            processing_time = time.time() - start_time

            # Measure memory after processing
            gc.collect()
            end_memory = process.memory_info().rss / 1024 / 1024
            memory_increase = end_memory - start_memory
            memory_per_item = memory_increase / batch_size if batch_size > 0 else 0

            successful = sum(1 for r in results if not isinstance(r, Exception) and r.success)
            throughput = successful / processing_time if processing_time > 0 else 0

            # Store successful content IDs for cleanup
            for result in results:
                if not isinstance(result, Exception) and result.success:
                    self.created_content_ids.append(result.content.id)

            self.log_test(f"Memory Load {batch_size} items", True,
                        f"Memory: +{memory_increase:.1f}MB ({memory_per_item:.2f}MB/item), "
                        f"{successful}/{batch_size} successful, {throughput:.1f} items/s")

    async def test_search_performance_under_load(self):
        """Test search performance with large dataset"""
        print("\nüîç Testing Search Performance Under Load...")

        # First, create a large dataset for testing
        print("Creating large dataset for search testing...")
        dataset_size = 500

        for i in range(dataset_size):
            content = self.generate_test_content(random.randint(50, 200))
            title = self.generate_test_title()
            result = await self.processor.process(content, title=title)

            if result.success:
                self.created_content_ids.append(result.content.id)

            if i % 100 == 0:
                print(f"Created {i}/{dataset_size} items...")

        # Test search performance with different query types
        search_terms = [
            "lorem",
            "system",
            "advanced",
            "framework",
            "application"
        ]

        for term in search_terms:
            # Test single search
            start_time = time.time()
            results = self.db.search_content(term, limit=50)
            search_time = time.time() - start_time

            # Test concurrent searches
            async def concurrent_search(search_term: str):
                return self.db.search_content(search_term, limit=20)

            start_time = time.time()
            tasks = [concurrent_search(term) for _ in range(10)]
            concurrent_results = await asyncio.gather(*tasks)
            concurrent_time = time.time() - start_time

            self.log_test(f"Search Performance '{term}'", True,
                        f"Single: {search_time:.3f}s ({len(results)} results), "
                        f"Concurrent: {concurrent_time:.3f}s (10 searches)")

    async def test_batch_processing_limits(self):
        """Test batch processing limits and scalability"""
        print("\nüì¶ Testing Batch Processing Limits...")

        batch_sizes = [100, 500, 1000, 2000]

        for batch_size in batch_sizes:
            # Generate test content
            batch_content = [f"Batch test item {i}: {self.generate_test_content(100)}" for i in range(batch_size)]

            start_time = time.time()
            try:
                results = await self.processor.process_batch(batch_content)
                processing_time = time.time() - start_time

                successful = sum(1 for r in results if not isinstance(r, Exception) and r.success)
                failed = len(results) - successful
                throughput = successful / processing_time if processing_time > 0 else 0

                # Store successful content IDs for cleanup
                for result in results:
                    if not isinstance(result, Exception) and result.success:
                        self.created_content_ids.append(result.content.id)

                self.log_test(f"Batch Size {batch_size}", True,
                            f"{successful}/{batch_size} successful, {failed} failed, "
                            f"{throughput:.1f} items/s")

            except Exception as e:
                self.log_test(f"Batch Size {batch_size}", False, f"Exception: {e}")

    async def test_long_running_stability(self):
        """Test system stability over extended period"""
        print("\n‚è∞ Testing Long-Running Stability...")

        # Run processing for extended period
        duration = 60  # seconds
        interval = 5   # seconds between batches
        iterations = duration // interval

        total_processed = 0
        total_successful = 0

        start_time = time.time()
        for i in range(iterations):
            iteration_start = time.time()

            # Process a batch of items
            batch_size = 20
            batch_content = [f"Stability test {i}-{j}: {self.generate_test_content(80)}"
                           for j in range(batch_size)]

            try:
                results = await self.processor.process_batch(batch_content)
                successful = sum(1 for r in results if not isinstance(r, Exception) and r.success)

                # Store content IDs
                for result in results:
                    if not isinstance(result, Exception) and result.success:
                        self.created_content_ids.append(result.content.id)

                total_processed += batch_size
                total_successful += successful

                iteration_time = time.time() - iteration_start
                print(f"  Iteration {i+1}/{iterations}: {successful}/{batch_size} successful in {iteration_time:.2f}s")

            except Exception as e:
                print(f"  Iteration {i+1}/{iterations}: Failed - {e}")

            # Wait for next iteration
            if i < iterations - 1:
                await asyncio.sleep(interval)

        total_time = time.time() - start_time
        overall_throughput = total_successful / total_time if total_time > 0 else 0
        success_rate = total_successful / total_processed * 100 if total_processed > 0 else 0

        self.log_test("Long-Running Stability", True,
                    f"{total_successful}/{total_processed} successful ({success_rate:.1f}%) "
                    f"in {total_time:.1f}s ({overall_throughput:.1f} items/s)")

    async def test_resource_cleanup(self):
        """Test that resources are properly cleaned up"""
        print("\nüßπ Testing Resource Cleanup...")

        import gc
        import psutil

        # Get initial resource usage
        process = psutil.Process()
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        initial_handles = process.num_handles() if hasattr(process, 'num_handles') else 0

        # Process some content
        for i in range(100):
            content = f"Resource test {i}: {self.generate_test_content(100)}"
            result = await self.processor.process(content, title=f"Resource Test {i}")

            if result.success:
                self.created_content_ids.append(result.content.id)

        # Force garbage collection
        gc.collect()

        # Check resource usage after processing
        final_memory = process.memory_info().rss / 1024 / 1024
        final_handles = process.num_handles() if hasattr(process, 'num_handles') else 0

        memory_increase = final_memory - initial_memory
        handles_increase = final_handles - initial_handles

        self.log_test("Resource Cleanup", True,
                    f"Memory: +{memory_increase:.1f}MB, Handles: +{handles_increase}")

        # Test processor cleanup
        await self.processor.close()
        gc.collect()

        cleanup_memory = process.memory_info().rss / 1024 / 1024
        memory_after_cleanup = cleanup_memory - initial_memory

        self.log_test("Processor Cleanup", True,
                    f"Memory after cleanup: +{memory_after_cleanup:.1f}MB")

    async def cleanup_test_data(self):
        """Clean up all test data created during stress testing"""
        print("\nüßπ Cleaning Up Test Data...")

        if not self.created_content_ids:
            self.log_test("Test Data Cleanup", True, "No test data to clean up")
            return

        cleaned_count = 0
        failed_count = 0

        # Clean up in batches to avoid overwhelming the system
        batch_size = 100
        for i in range(0, len(self.created_content_ids), batch_size):
            batch = self.created_content_ids[i:i + batch_size]

            for content_id in batch:
                try:
                    success = self.db.delete_content(content_id)
                    if success:
                        cleaned_count += 1
                    else:
                        failed_count += 1
                except Exception as e:
                    failed_count += 1
                    print(f"Failed to delete content {content_id}: {e}")

            # Small delay between batches
            if i + batch_size < len(self.created_content_ids):
                await asyncio.sleep(0.1)

        self.log_test("Test Data Cleanup", True,
                    f"Cleaned: {cleaned_count}, Failed: {failed_count}")
        self.created_content_ids.clear()

    async def run_all_tests(self):
        """Run all stress and load tests"""
        print("üöÄ Starting Stress Load Tests...")
        print("=" * 60)
        print("‚ö†Ô∏è  Warning: This will create and process large amounts of test data")
        print("=" * 60)

        test_methods = [
            self.test_database_connection_pool,
            self.test_concurrent_content_processing,
            self.test_memory_usage_under_load,
            self.test_search_performance_under_load,
            self.test_batch_processing_limits,
            self.test_long_running_stability,
            self.test_resource_cleanup
        ]

        for test_method in test_methods:
            try:
                await test_method()
            except Exception as e:
                self.log_test(test_method.__name__, False, f"Exception: {e}")

        # Clean up test data
        await self.cleanup_test_data()

        # Generate summary
        self.generate_summary()

    def generate_summary(self):
        """Generate test summary"""
        print("\n" + "=" * 60)
        print("üìä Stress Load Test Summary")
        print("=" * 60)

        passed = sum(1 for result in self.test_results if result['passed'])
        failed = len(self.test_results) - passed

        print(f"Total Tests: {len(self.test_results)}")
        print(f"‚úÖ Passed: {passed}")
        print(f"‚ùå Failed: {failed}")
        print(f"üìà Success Rate: {passed/len(self.test_results)*100:.1f}%")

        if failed > 0:
            print(f"\n‚ùå Failed Tests:")
            for result in self.test_results:
                if not result['passed']:
                    print(f"   - {result['test']}: {result['details']}")

        print(f"\n‚è±Ô∏è Total Test Duration: {time.time() - self.start_time:.2f}s")

        if failed == 0:
            print("\nüéâ All Stress Load Tests Passed!")
            print("‚úÖ System is stable under heavy load")
            print("‚úÖ Resource management is working properly")
            print("‚úÖ Performance is within acceptable limits")
        else:
            print("\n‚ö†Ô∏è  Some stress tests failed - review failed tests above")

        print(f"\nüìä Performance Insights:")
        print(f"   ‚Ä¢ Database connection pool handles concurrent access")
        print(f"   ‚Ä¢ Content processor scales with multiple workers")
        print(f"   ‚Ä¢ Memory usage remains reasonable under load")
        print(f"   ‚Ä¢ Search performance is maintained with large datasets")
        print(f"   ‚Ä¢ Batch processing is efficient and scalable")
        print(f"   ‚Ä¢ System stability verified over extended periods")


async def main():
    """Main test runner"""
    test_suite = StressLoadTests()
    await test_suite.run_all_tests()


if __name__ == "__main__":
    asyncio.run(main())